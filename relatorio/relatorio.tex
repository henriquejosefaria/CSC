\documentclass[a4paper, 12pt]{article}

\usepackage[portuges]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm,amssymb}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{url}
\usepackage{float}
\usepackage{subcaption}

\newtheorem{defin}{Definição}[section]
\newtheorem{obs}{Observação}[section]
\newtheorem{teo}{Teorema}[section]
\newtheorem{nota}{Nota}[section]
\newtheorem{lema}{Lema}[section]



%Python code

\usepackage{listings}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}


\setlength{\unitlength}{1cm}
\thicklines

\begin{document}

\begin{titlepage}
	\begin{center}
		
		\begin{figure}[!htb]
			\centering
			\includegraphics[width=5cm]{uminho}
			\label{Rotulo}
		\end{figure}
		%\vspace{1cm}
		
		\textbf{\Huge{Universidade do Minho}}\\
		\vspace{10pt}
		\large{Escola de Ciências da Universidade do Minho}\\
		\large{Departamento de Informática}\\
		\vspace{10pt}
		\normalsize{Mestrado em Matemática e Computação}\\
		\normalsize{Mestrado Integrado em Engenharia Informática}\\
		\vspace{2cm}
		\textbf{\Large{Redes Neuronais Recorrentes para previsão do fluxo de tráfego rodoviário}}\\
		\vspace{2cm}
	\end{center}
	
	\begin{center}
		\textbf{Alunos:}
		\vspace{0,1cm}
		\\Andreia Costa (PG37013) \\Henrique Faria (A82200) \\ Paulo Barbosa (PG40160) \\ Rui Teixeira (PG37021)\\
		\vspace{1cm}
		\textbf{Docentes:} \\
		Bruno Fernandes\\ 
		Victor Alves \\
		\vspace{1cm}
		\textbf{Unidade Curricular:} Classificadores e Sistemas Conexionistas
	\end{center}
	\vspace{1cm}
	\begin{center}
		Maio\\
		2020
	\end{center}
\end{titlepage}

\newpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\newpage
\tableofcontents
\thispagestyle{empty}

\newpage
\pagenumbering{arabic}

\section{Introdução}


\newpage

\section{\textit{Dataset}}

Aquando da apresentação do presente trabalho foram disponibilizados dados referentes a duas cidades: Braga e Porto, sendo que o grupo escolheu os dados relativos à cidade de Braga para trabalhar.

Os dados encontram-se distribuídos em $4$ \textit{datasets}:

\begin{itemize}
	\item \textit{Traffic Flow Braga Until 20191231};
	\item \textit{Traffic Incidents Braga Until 20191231};
	\item \textit{Weather Braga Descriptions Until 20191231};
	\item \textit{Weather Braga Until 20191231}.
\end{itemize}

Todos os \textit{datasets} contêm dados relativos ao período entre $15$ Janeiro $2019$ e $31$ Dezembro $2019$.

\subsection{\textit{Traffic Flow Braga}}

O \textit{dataset "Traffic Flow Braga" } é constituído pelos seguintes atributos:

\begin{itemize}
	\item $city\_name$;
	\item $road\_num$;
	\item $road\_name$;
	\item $functional\_road\_class\_desc$;
	\item $current\_speed$;
	\item $free\_flow\_speed$;
	\item $speed\_diff$;
	\item $current\_travel\_time$;
	\item $free_flow\_travel\_time$;
	\item $time\_diff$;
	\item $creation\_date$.
\end{itemize}

\subsection{\textit{Traffic Incidents Braga}}

\begin{itemize}
	\item $city\_name$;
	\item $description$;
	\item $cause\_of\_incident$;
	\item $from\_road$;
	\item $to\_road$;
	\item $affected\_roads$;
	\item $incident\_category\_desc$;
	\item $magnitude\_of\_delay\_desc$;
	\item $length\_in\_meters$;
	\item $delay\_in\_seconds$;
	\item $incident\_date$;
	\item $latitude$;
	\item $longitude$.
\end{itemize}

\subsection{\textit{Weather Braga Descriptions}}

\begin{itemize}
	\item $city\_name$;
	\item $cloudiness$;
	\item $atmosphere$;
	\item $snow$;
	\item $thunderstorm$;
	\item $rain$;
	\item $sunrise$;
	\item $sunset$;
	\item $creation\_date$.
\end{itemize}

\subsection{\textit{Weather Braga}}

\begin{itemize}
	\item $city\_name$;
	\item $temperature$;
	\item $atmospheric\_pressure$;
	\item $humidity$;
	\item $wind\_speed$;
	\item $clouds$;
	\item $precipitation$;
	\item $current\_luminosity$;
	\item $sunrise$;
	\item $sunset$;
	\item $creation\_date$.
\end{itemize}

\subsection{Preparação dos dados}
\label{section:falta}

Após análise dos quatro \textit{datasets} concluiu-se que, antes de se desenvolver o modelo para a previsão da \textit{feature speed\_diff}, era necessário fazer uma prévia preparação dos dados.

Começou-se por fazer um tratamento inicial do \textit{dataset Traffic\_Incidents}. Para isso, a cada incidente atribuiu-se os vários valores da coluna \textit{road\_num}, para que posteriormente fosse possível avaliar a distância entre os incidentes e as ruas em estudo e verificar de que forma estes incidentes afetam uma determinada rua.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{Traffic_Incidents}
	\caption{Preparação do \textit{dataset Traffic\_Incidentes}.}
\end{figure}

De seguida, recorrendo à latitude e longitude dos diferentes acontecimentos, calculou-se a distância dos incidentes a cada uma das ruas, para perceber o raio de influência dos incidentes para as ruas em estudo, de modo, a ser possível, posteriormente, remover incidentes que se encontrem muito afastados das ruas em estudo. Para isso, recorreu-se à fórmula:

$$dist(A, B) = R * \arccos (sin (lat_A) * \sin (lat_B) + \cos (lat_A) * \cos (lat_B) * \cos (lon_A-lon_B)). $$

onde,

\begin{itemize}
	\item \textbf{$lat_A$:} latitude do ponto A;
	\item \textbf{$lat_B$:} latitude do ponto B;
	\item \textbf{$lon_A$:} longitude do ponto A;
	\item \textbf{$lon_B$:} longitude do ponto B;
	\item \textbf{$R$:} raio da Terra.
\end{itemize}

tendo-se implementado o seguinte código.

\begin{lstlisting}[language=Python]
import pandas as pd
from math import radians, sin, cos, atan2, sqrt

df = pd.read_csv('Traffic_Incidents.csv', delimiter = ',', error_bad_lines = False, encoding = 'ISO-8859-1')

def distance(p1, n):
	R = 6371.0
	if n == 1:
	lat2 = radians(41.548331)
	lon2 = radians(-8.421298)
	elif n == 2:
	lat2 = radians(41.551356)
	lon2 = radians(-8.420001)
	elif n == 3:
	lat2 = radians(41.546639)
	lon2 = radians(-8.433517)
	else:
	lat2 = radians(41.508849)
	lon2 = radians(-8.462299)
	lat1, lon1 = radians(p1[0]), radians(p1[1])
	dlon = lon2 - lon1
	dlat = lat2 - lat1
	a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
	c = 2 * atan2(sqrt(a), sqrt(1 - a))
	distance = R * c
return distance

df['Distance'] = df.apply(lambda row: distance((row['latitude'],row['longitude']), row['road_num']), axis=1)
\end{lstlisting}

Após calculadas todas as distâncias fez-se um tratamento estatístico, tendo-se obtido os seguintes resultados:

\begin{itemize}
	\item ${max}= 6313,251$;
	\item ${min}= 0,0228$;
	\item ${mean}= 4,507$;
	\item ${standard \ deviation}= 81,789$.
\end{itemize}

Através dos resultados obtidos é possível verificar que existem dados mal classificados, uma vez que, sendo os dados recolhidos referentes apenas à cidade de Braga era impossível que a distância máxima dos incidentes às ruas fosse de cerca de $6313$ km. Fez-se um estudo desta informação e verificou-se que estes dados dizem respeito a uma cidade que não pertence a Braga.

\begin{figure}[H]
	\centering
	\includegraphics[width=14cm]{EUA}
	\caption{Dado mal classificado.}
\end{figure}

Devido a este facto, optou-se por remover alguns dados do \textit{dataset}. Uma vez que a distância é medida em linha reta utilizou-se como \textit{threshold}, para remover dados, vários valores, nomeadamente, $0.5$, $1$ e $1.5$.

Após feito este tratamento procedeu-se à preparação dos dados referentes aos restantes \textit{datasets}, com o intuito de se obter, no final, um único \textit{dataset}.

Começou-se por fazer o tratamento do \textit{dataset Weather\_Descriptions\_Braga}, tendo-se removido as colunas: \textit{city\_name}, \textit{snow} e \textit{cloudiness}. A coluna \textit{snow} apresentava apenas \textit{missing values}, daí se ter optado pela sua remoção. Relativamente à  coluna \textit{cloudiness}, optou-se por fazer a remoção da mesma, uma vez que existe uma coluna que está diretamente relacionada com esta, a coluna \textit{cloud}, pertencente ao \textit{dataset Weather\_Braga}, e que não apresenta \textit{missing values}.

De seguida, procedeu-se à remoção das colunas \textit{city\_name} e \textit{precipitation} do \textit{dataset Weather\_Braga}. A remoção da coluna \textit{precipitation} deveu-se ao facto desta apenas apresentar um único valor, o $0$. 

De modo a unir o resultado da preparação dos dados feita para os \textit{datasets} anteriores, recorreu-se ao nodo \textit{Joiner}, e uniram-se os \textit{datasets} por \textit{creation\_date}, tendo-se efetuado, de seguida, a extração da data e do tempo, tendo-se extraído: o mês como uma variável numérica, a hora, o dia do mês e o dia da semana.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{weather}
	\caption{Preparação dos \textit{datasets Weather\_Descriptions\_Braga} e \textit{Weather\_Braga}.}
\end{figure}

De seguida, procedeu-se à preparação do \textit{dataset Traffic\_Flow\_Braga}, procedendo-se à remoção das colunas \textit{city\_name} e \textit{road\_name}, seguida da extração da data e hora, à semelhança do que foi feito para o \textit{dataset} anterior.

O \textit{dataset Traffic\_Flow\_Braga} tinha registos de $20$ em $20$ minutos e o \textit{dataset} obtido anteriormente tinha registos de hora em hora, assim, de modo a unir o \textit{dataset} com os dados relativos ao \textit{Weather}, optou-se por agrupar os registos do \textit{dataset Traffic\_Flow\_Braga} por hora, mês, dia e rua, recorrendo-se ao nodo \textit{GroupBy}, tendo-se feito a média de todos os valores numéricos para as restantes colunas.

Assim, de modo a juntar este \textit{dataset} ao obtido anteriormente, recorreu-se ao nodo \textit{Joiner}, unindo-se os \textit{datasets} por hora, dia do mês e mês, fazendo-se um \textit{Left Outer Join}. Optou-se por fazer um \textit{Left Outer Join}, uma vez que não se queriam as condições atmosféricas de registos em que não havia dados de tráfego.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{join}
	\caption{Preparação do \textit{dataset Traffic\_Flow\_Braga}.}
\end{figure}

Após a junção dos \textit{datasets}, eliminou-se a coluna \textit{creation\_date} e transformaram-se os valores "N/A", das colunas \textit{rain}, \textit{thunderstorm} e \textit{atmosphere}, em \textit{missing values}, recorrendo ao nodo \textit{String Manipulation}. De seguida, quando não existiam valores na coluna \textit{rain} atribuia-se o valor da coluna \textit{thunderstorm}, uma vez que as \textit{labels} da coluna \textit{thunderstorm} faziam referência ao estado da chuva. De seguida, alteraram-se alguns dos valores ($"trovoada \ com \ chuva \ fraca" \rightarrow "chuva \ fraca"$, $"trovoada \ com \ chuva \ forte" \rightarrow "chuva \ forte"$ e $"trovoada" \rightarrow "chuva"$), tendo-se removido, no final, a coluna \textit{thunderstorm}. Por fim, eliminaram-se as colunas \textit{sunrise} e \textit{sunset}, uma vez que não se achou que estas colunas eram relevantes para prever o \textit{speed\_diff}.

\begin{figure}[H]
	\centering
	\includegraphics[width=15cm]{prep}
	\caption{Preparação dos dados.}
\end{figure}

Por fim, tratou-se o \textit{dataset Traffic\_Incidents\_Braga} cuja \textit{feature Distance} tinha apenas valores inferiores a $0.5 \ km$. Recorrendo à coluna \textit{incident\_date}, procedeu-se à extração do dia, da hora e do mês e removeram-se colunas irrelevantes, nomeadamente, as colunas \textit{city\_name}, \textit{incident\_date} e \textit{cause\_of\_incident}, uma vez que esta última apresentava maioritariamente \textit{missing values}.

Uma vez que a coluna \textit{Distance} já inclui informação que permite relacionar a influência de um dado inicidente com as ruas em estudo, optou-se por remover as colunas: \textit{from\_road}, \textit{to\_road}, \textit{affected\_roads}, \textit{latitute} e \textit{longitude}.

Após tratado este \textit{dataset}, e recorrendo ao nodo \textit{Joiner}, uniu-se este \textit{dataset} com o obtido anteriormente por hora, dia do mês, mês e \textit{road\_num}. Deste modo, uniram-se os $4$ \textit{datasets} iniciais num único.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{Incident}
	\caption{Preparação do \textit{dataset} resultante do tratamento do \textit{dataset Traffic\_Incidents\_Braga}.}
\end{figure}

Após se ter apenas um \textit{dataset} verificou-se que este continha $26$ colunas, o que se achou serem demasiadas. Assim, de modo a tornar o \textit{dataset} mais pequeno, recorreu-se ao nodo \textit{Rank Correlation} e avaliou-se a correlação que existia entre as diferentes colunas, tendo-se removido as seguintes: \textit{free\_flow\_speed}, \textit{current\_travel\_time}, \textit{free\_flow\_travel\_time }, \textit{atmospheric\_pressure}, \textit{humidity}, \textit{current\_luminosity} e \textit{magnitude\_of\_delay\_desc}. Deste modo, o \textit{dataset} ficou apenas com $18$ colunas.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{rank}
	\caption{Análise da correlação entre as diferentes \textit{features}.}
\end{figure}

Aos valores \textit{Undefined} da \textit{feature descriptions} atribui-se o valor \textit{Unknown Delay}, uma vez que estes têm significado semelhante.

De seguida, e tendo em conta que as colunas \textit{atmosphere} e \textit{rain} apresentam muitos \textit{missing values}, procedeu-se ao tratamento dos mesmos. 

Começou-se, então, por tratar os \textit{missing values} da coluna \textit{atmosphere}, uma vez que esta era a que apresentava menos \textit{missing values}, tendo-se separado o \textit{dataset} em dois, recorrendo ao nodo \textit{Rule-based Row Splitter}. Um \textit{dataset} apresenta a coluna \textit{atmosphere} apenas com \textit{missing values} e o outro apresenta a coluna \textit{atmosphere} com os vários valores. De seguida, utilizaram-se \textit{Random Forest} para fazer a previsão dos \textit{missing values}.

Com o intuito de perceber quais os melhores parâmetros a utilizar efetuou-se o \textit{tunning} do modelo.

\begin{figure}[H]
	\centering
	\includegraphics[width=15cm]{tunning}
	\caption{\textit{Tunning} do modelo.}
\end{figure}

Após efetuado o \textit{tunning} do modelo, concluiu-se que este apresentava melhores valores se fosse treinado com $60$ árvores e usando como critério de \textit{split} o \textit{Information Gain}, tendo-se uma \textit{accuracy} de cerca $99,5\%$

\begin{figure}[H]
	\centering
	\includegraphics[width=15cm]{melhores_params}
	\caption{Melhores parâmetros para construir o modelo.}
\end{figure}

Por fim, sabendo quais os melhores parâmetros, contruiu-se um novo modelo usando $100\%$ dos dados para o treinar.

\begin{figure}[H]
	\centering
	\includegraphics[width=15cm]{atmos}
	\caption{Previsão dos \textit{missing values} da \textit{feature atmosphere}.}
\end{figure}

Após feita a previsão dos \textit{missing values} para a \textit{feature atmosphere}, procedeu-se à previsão dos \textit{missing values} do atributo \textit{rain}, tendo-se utilizado o mesmo esquema para obter os melhores parâmetros, tendo-se obtido uma \textit{accuraccy} de cerca de $97,8\%$.

Para finalizar o tratamento de dados, no \textit{Knime}, recorrendo ao nodo \textit{Duplicate Row Filter}, eliminaram-se linhas repetidas e efetuou-se o \textit{Label Encoding} dos valores correspondentes às \textit{features}: \textit{Day of week (name)}, \textit{description}, \textit{incident\_category\_desc}, \textit{atmosphere} e \textit{rain}, uma vez que o objetivo é utilizar redes neuronais para prever o \textit{speed\_diff}, e estas apenas aceitam valores numéricos.

É de notar que, após feito todo este tratamento, existem colunas que apresentam \textit{missing values}. No entanto, estes \textit{missing values} ocorrem nas colunas correspondentes aos incidentes, porque não houve incidentes naquela hora, numa distância inferior a $0.5$ km. Estes \textit{missing values} foram substituídos por um valor \textit{default}, $-1$.

Por fim, observou-se que existiam dias com horas repetidas, devido ao facto de para uma mesma hora existir mais do que um incidente. Assim, para que isto não acontecesse, recorreu-se ao nodo \textit{GroupBy} para agrupar os incidentes, optando-se por ficar com o incidente que estava mais próximo da rua em estudo, ou seja, o incidente que apresentava na coluna \textit{Distance} o valor mais baixo.

\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{fim}
	\caption{Tratamento final.}
\end{figure}

Após feito este tratamento, recorrendo ao nodo \textit{Pie chart (local)} percebeu-se que o \textit{dataset} apresentava dias e horas em falta como, por exemplo, o mês de Março.

\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{mes_dias}
	\caption{Dias em falta no \textit{dataset}.}
\end{figure}

\section{Problema}

O objetivo do trabalho consiste em utilizar Redes Neuronais para fazer previsão do fluxo de tráfego rodoviário. Tendo em conta os dados disponibilizados, o grupo optou por fazer a previsão da \textit{feature speed\_diff} de uma dada rua, baseando-se em 3 dias para prever o dia seguinte. Optou-se por fazer previsões para as ruas em separado, uma vez que se acredita que o fluxo de tráfego das ruas é distinto entre elas. Para isso, dividiu-se o \textit{dataset} original em $4$, sendo que cada \textit{dataset} correspondia a uma determinada rua.

Uma vez que se trata de um problema de séries temporais, optou-se por implementar um modelo \textit{multistep} e \textit{multivariate} que utiliza \textit{LSTM}'s.

\subsection{Resolução do Problema}

Para resolver este problema era então necessário perceber quais os dias que estavam incompletos, ou seja, quais os dias que não tinham as $24$ horas preenchidas, procedendo-se à eliminação destes, com o intuito de se ter um \textit{dataset} sem "buracos". Para isso, implementou-se o seguinte algoritmo:

\begin{lstlisting}[language=Python]
i=0
for i in range(1,13):
	for j in range(1,32):
	L=df[(df['Month (number)']==i)&(df['Day of month']==j)].dropna()
	L1=L[['Month (number)','Day of month','Hour','road_num']]
	L1 = L1.drop_duplicates()
	indexNames = df[(df['Month (number)']==i)&(df['Day of month']==j)].index
	if len(L1)<24:
	try:
		df.drop(indexNames, inplace=True)
	except:
		pass
\end{lstlisting}

Visto que no final do capítulo \ref{section:falta} verificámos que existiam dias em falta e como se pretende que sejam dados ao modelo, como \textit{input}, $3$ dias para prever o próximo, quer garantir-se que, de facto, esses $4$ dias são seguidos, ou seja, que os $3$ dias dados como \textit{input} mais o dia a prever sejam seguidos, evitando que ocorram situações em que o primeiro dia seja, por exemplo, $16$ de Janeiro e o dia a prever seja $30$ de Janeiro.

Assim, para ter a certeza que se treina o modelo com dias consecutivos, percorreu-se o \textit{dataset} construindo blocos de $4$ dias, para verificar se estes $4$ dias são seguidos, calcula-se a diferença entre o último dia do bloco e o primeiro e, dependendo do mês, verifica-se se é $4$. Note-se, no entanto, que se para um dado bloco tivermos dias de meses distintos, esta diferença é negativa, sendo este problema corrigido dependendo do mês em causa.

Antes de se aplicar o seguinte algoritmo, ordenou-se o \textit{dataset} por mês, dia e hora.

\begin{lstlisting}[language=Python]
n_future = 24 # next 24 hours speed diff forecast
n_past = 24*3 # Past 3 days

x_train = []
y_train = []
label = df_1['speed_diff']

for i in range(0,len(df_1)-n_past-n_future+1):
	dias = df_1.iloc[i : i + n_past+24]
	mes = dias.iloc[0]['Month (number)']
	dia_1 = dias.iloc[0]['Day of month']
	dia_4 = dias.iloc[24*3+1]['Day of month']
	if (mes == 4 or mes == 6 or mes == 9 or mes == 11) and (dia_4 - dia_1 == 3 or dia_4 - dia_1 == -29):
		x_train.append(df_1.iloc[i : i + n_past])
		y_train.append(label.iloc[i + n_past : i + n_past + n_future ])
	elif (mes == 1 or mes == 3 or mes == 5 or mes == 7 or mes == 8 or mes == 10 or mes == 12) and (dia_4 - dia_1 == 3 or dia_4 - dia_1 == -28):
		x_train.append(df_1.iloc[i : i + n_past])
		y_train.append(label.iloc[i + n_past : i + n_past + n_future ])
	elif mes == 2 and (dia_4 - dia_1 == 3 or dia_4 - dia_1 == -26):
		x_train.append(df_1.iloc[i : i + n_past])
		y_train.append(label.iloc[i + n_past : i + n_past + n_future ])
\end{lstlisting}

Sabendo-se que cada \textit{input} é constituído por $3$ dias seguidos, com as $24$ horas completas e, portante, as colunas \textit{Month (number)}, \textit{Day of month} e \textit{Hour} já não são relevantes, tendo-se feito a remoção das mesmas. Além disso, removeram-se as colunas \textit{Day of week (name)}, \textit{incident\_category\_desc} e \textit{Distance}. Esta última foi removida, uma vez que apenas serviu para saber quais os incidentes que deviam permanecer no \textit{dataset}.

Após feito todo o tratamento acima mencionado, o \textit{dataset} está pronto para ser aplicado a uma rede que permita prever a \textit{feature speed\_diff}.

\section{Modelo}

O problema que se pretende resolver é um problema de séries temporais, como já foi anteriormente referido. Deste modo, para prever a \textit{feature speed\_diff} optou-se por construir um modelo \textit{multistep} e \textit{multivariate} que utiliza \textit{LSTM}'s.

Tendo em conta que o objetivo é utilizar $3$ dias para prever as $24$ horas seguintes, utilizando $11$ \textit{features}, definiu-se como $input_shape = (24*3,11)$.

Antes de se começar a treinar o modelo procedeu-se à normalização dos dados:

\begin{lstlisting}[language=Python]
# Features normalization
scalers=[]
for i in range(11):
sc = MinMaxScaler(feature_range=(0,1))
x_train[:,i] = sc.fit_transform(x_train[:,i])
x_test[:,i] = sc.fit_transform(x_test[:,i])
scalers.append(sc)

# Labels normalization
sc1 = MinMaxScaler(feature_range=(0,1))
y_train = sc1.fit_transform(y_train)
y_test_n = sc1.fit_transform(y_test)
\end{lstlisting}

Uma vez que os dados estavam normalizados no intervalo $[0,1]$ recorreu-se à função de ativação \textit{sigmoid}.

Relativamente às métricas utilizadas, utilizou-se como \textit{loss} o \textit{mean square error} e como métrica o \textit{root mean square error}. Estas foram as métricas escolhidas, uma vez que o  objetivo era penalizar erros grandes, e estas são as melhores métricas para o fazer.

Assim, recorrendo a técnicas de intuição e experimentação construiu-se o seguinte modelo:

\begin{lstlisting}[language=Python]
model = Sequential()
model.add(CuDNNLSTM(units=24*3, return_sequences=True, input_shape = (24*3,11) ) )
model.add(Dropout(0.2))
model.add(CuDNNLSTM(24*3 , return_sequences=True))
model.add(Dropout(0.2))
model.add(CuDNNLSTM(24*3, return_sequences=True))
model.add(Dropout(0.2))
model.add(CuDNNLSTM(24*2))
model.add(Dropout(0.2))
model.add(Dense(24,activation='sigmoid'))
model.compile(optimizer='adam', loss='mean_squared_error',metrics=rmse)
callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)
history=model.fit(x_train, y_train, validation_data=(x_test, y_test_n), epochs=1000, callbacks=[callback])
\end{lstlisting}

\subsection{Avaliação do comportamento do modelo}

Após construído o modelo, procedeu-se a um conjunto de testes, utilizando $200$ dados de teste, com o intuito de ser possível avaliar o comportamento do mesmo.

Primeiro determinou-se, para os 200 dados de teste, o número de ocorrências de cada dia da semana.
Para se perceber se o comportamento do modelo era o esperado procedeu-se à utilização de duas métricas de erro:

\begin{enumerate}
	\item A média dos erros, para cada dia da semana;
	\item A diferença, absoluta, máxima entre o valor real e o valor previsto, para cada dia da semana.
\end{enumerate}

Ambas as métricas de erro parecem ser úteis para perceber o comportamento do modelo, no entanto, a segunda métrica talvez seja a que melhor representa o comportamento do mesmo. Isto porque, na sua maioria, os valores do \textit{speed\_diff} são $0$ e, portanto, nesses casos, o modelo facilmente prevê esses valores. Assim, o que se pretende é perceber o comportamento do modelo quando o valor do \textit{speed diff} é elevado.

\subsubsection{Rua 1}

Começou-se por treinar o modelo com os dados da rua $1$, e fazer a previsão para essa mesma rua. 

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/curvas_aprend_1.png}
	\caption{Curvas de aprendizagem.}
	\label{figure:curvas_aprend_1}
\end{figure}

Observando a Figura \ref{figure:curvas_aprend_1}, conclui-se que o modelo criado apresenta \textit{underfitting}, uma vez que as curvas de aprendizagem são distintas uma da outra. Pode ainda referir-se que, apesar de existir \textit{underfitting}, é provável que com o aumento do número de épocas não se observe uma convergência das curvas, uma vez que se observa que ambas as curvas parecem ter estagnado, o que pode evidenciar que o modelo não está a aprender.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/real_prev_1.png}
	\caption{Valores reais vs previstos, em 24 horas.}
	\label{figure:real_prev_1}
\end{figure}

A Figura \ref{figure:real_prev_1} permite comparar, graficamente o valor teórico com o valor real, durante um período de $24$ horas. Ora, através da análise do gráfico observa-se que não existe uma grande discrepância entre o valor real e o valor previsto. Pelo que se pode considerar que o modelo construído faz boas previsões.

Para melhor perceber os valores do gráfico, analisem-se os valores concretos, previstos e reais, para dia representado no gráfico:

Hora:  0 . Real:  0.0 Previsto:  0.88026047\\
Hora:  1 . Real:  0.0 Previsto:  0.7328456\\
Hora:  2 . Real:  6.0 Previsto:  3.3725905\\
Hora:  3 . Real:  2.33 Previsto:  1.1033564\\
Hora:  4 . Real:  0.0 Previsto:  0.023271516\\
Hora:  5 . Real:  0.0 Previsto:  0.0001698993\\
Hora:  6 . Real:  0.0 Previsto:  0.00014231614\\
Hora:  7 . Real:  0.0 Previsto:  0.012032909\\
Hora:  8 . Real:  0.0 Previsto:  0.000106166335\\
Hora:  9 . Real:  0.0 Previsto:  0.00021103116\\
Hora:  10 . Real:  0.0 Previsto:  7.701842e-05\\
Hora:  11 . Real:  0.0 Previsto:  1.9046819e-06\\
Hora:  12 . Real:  0.0 Previsto:  0.0008848502\\
Hora:  13 . Real:  1.333 Previsto:  0.32069737\\
Hora:  14 . Real:  3.333 Previsto:  2.1331909\\
Hora:  15 . Real:  1.67 Previsto:  1.2618717\\
Hora:  16 . Real:  2.25 Previsto:  1.9521923\\
Hora:  17 . Real:  5.67 Previsto:  3.6571324\\
Hora:  18 . Real:  0.0 Previsto:  0.2529186\\
Hora:  19 . Real:  0.0 Previsto:  0.36589038\\
Hora:  20 . Real:  1.67Previsto:  0.857706\\
Hora:  21 . Real:  2.0 Previsto:  1.1876951\\
Hora:  22 . Real:  3.33 Previsto:  3.1549797\\
Hora:  23 . Real:  2.67 Previsto:  2.0546534\\

Por fim, faça-se uma análise dos erros obtidos. Após calculados os diferentes valores do erro, obtiveram-se os seguinte resultados:

\begin{table}[H]
\centering
\begin{tabular}{||c||c|c||}
	\hline\hline
	 & \textit{Average Diff} & \textit{Max Diff} \\
	\hline\hline
	29 Segundas & 
	0.45041437349683916 & 2.688410424907837\\
	\hline
	32 Terças  &
	0.667550546634858 & 3.34442551806569\\
	\hline
	21 Quartas & 
	0.7256597869759804 & 3.54161070084286
 \\
	\hline
	28 Quintas  & 
	0.8709156546679246 & 3.574933966435591
   \\
	\hline
	26 Sextas & 
	0.6481754712763175 & 3.0730847400820447
 \\
	\hline
	40 Sábados  & 
	0.8333129548379334 & 3.8209066510200493   \\
	\hline
	24 Domingos & 0.3614912258109369 & 2.909281443294168 \\
	\hline\hline
\end{tabular}
\label{table:rua1}
\caption{Cálculo dos erros.}
\end{table}

Analizando os resultados apresentados na Tabela \ref{table:rua1}, conclui-se que a pior previsão feita erra em cerca de $3 \ km/h$, o que se pode considerar aceitável.

Veja-se, agora, o comportamento do modelo treinado com dados da rua $1$, para fazer previsões para as restantes ruas.

\vspace{0.5cm}
\textbf{Usar modelo da rua 1 para fazer previsões para a rua 2}

De seguida, apresenta-se, graficamente, os resultados obtidos, para o primeiro dia de teste:

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/real_prev_mod1_rua2.png}
	\caption{Valores reais vs previstos, em 24 horas.}
\end{figure}

Relativamente aos erros obtidos, foram os seguintes:

\begin{table}[H]
	\centering
	\begin{tabular}{||c||c|c||}
		\hline\hline
		& \textit{Average Diff} & \textit{Max Diff} \\
		\hline\hline
		29 Segundas & 
		1.4141310389214723 & 5.4525856934502\\
		\hline
		32 Terças  &
		2.4944998488697543 & 8.16405452179511\\
		\hline
		21 Quartas & 2.062510539569396 & 6.801310798241978	\\
		\hline
		28 Quintas  & 2.0869987113999438 & 6.89385905070646	\\
		\hline
		26 Sextas & 2.0705880075275753 & 7.1521253924084025	\\
		\hline
		40 Sábados  & 2.1271022976475544 &7.631666235677035  \\
		\hline
		24 Domingos & 1.3197363545949343 & 5.627886255043933\\
		\hline\hline
	\end{tabular}
	\label{table:mod1_rua2}
	\caption{Cálculo dos erros.}
\end{table}

Ora, analisando a Tabela \ref{table:mod1_rua2}, conclui-se que o modelo construído para a rua $1$ não deve ser utilizado para fazer previsões para a rua $2$.

\vspace{0.5cm}
\textbf{Usar modelo da rua 1 para fazer previsões para a rua 3}

De seguida, apresenta-se, graficamente, os resultados obtidos, para o primeiro dia de teste:

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/real_prev_mod1_rua3.png}
	\caption{Valores reais vs previstos, em 24 horas.}
\end{figure}

Relativamente aos erros obtidos, foram os seguintes:

\begin{table}[H]
	\centering
	\begin{tabular}{||c||c|c||}
		\hline\hline
		& \textit{Average Diff} & \textit{Max Diff} \\
		\hline\hline
		29 Segundas & 4.968594437572376 & 21.611381565138636 \\
		\hline
		32 Terças  &4.512921544439047 & 20.73420555472391\\
		\hline
		21 Quartas & 4.851166798868657 & 18.831684388423337	\\
		\hline
		28 Quintas  & 4.639013167480982 &	17.884045215024216\\
		\hline
		26 Sextas & 4.004339738592879 & 15.851706346395257 \\
		\hline
		40 Sábados  & 5.0669990569940415 & 21.99666263190514 \\
		\hline
		24 Domingos & 3.638927058432079 & 13.069540181474318\\
		\hline\hline
	\end{tabular}
	\label{table:mod1_rua3}
	\caption{Cálculo dos erros.}
\end{table}

\vspace{0.5cm}
\textbf{Usar modelo da rua 1 para fazer previsões para a rua 4}

De seguida, apresenta-se, graficamente, os resultados obtidos, para o primeiro dia de teste:

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/real_prev_mod1_rua4.png}
	\caption{Valores reais vs previstos, em 24 horas.}
\end{figure}

Relativamente aos erros obtidos, foram os seguintes:

\begin{table}[H]
	\centering
	\begin{tabular}{||c||c|c||}
		\hline\hline
		& \textit{Average Diff} & \textit{Max Diff} \\
		\hline\hline
		29 Segundas & 4.041932785527517 & 15.000999822035086 \\
		\hline
		32 Terças  &6.127982964351863 & 22.09220023948531\\
		\hline
		21 Quartas & 6.060101547371708 & 20.905789931025378	\\
		\hline
		28 Quintas  & 6.963894699804549 & 21.725286395306515	\\
		\hline
		26 Sextas & 5.634002496531076 & 19.596345331894703 \\
		\hline
		40 Sábados  & 6.579623658131328 & 22.902688922073136 \\
		\hline
		24 Domingos & 3.0330747335502473 & 13.139625084538219\\
		\hline\hline
	\end{tabular}
	\label{table:mod1_rua4}
	\caption{Cálculo dos erros.}
\end{table}



\subsubsection{Rua 2}



\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/curvas_aprend_2.png}
	\caption{Curvas de aprendizagem.}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/real_prev_2.png}
	\caption{Valores reais vs previstos, em 24 horas.}
\end{figure}

\subsubsection{Rua 3}



\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/curvas_aprend_3.png}
	\caption{Curvas de aprendizagem.}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/real_prev_3.png}
	\caption{Valores reais vs previstos, em 24 horas.}
\end{figure}

\subsubsection{Rua 4}


\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/curvas_aprend_4.png}
	\caption{Curvas de aprendizagem.}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{resultados/real_prev_4.png}
	\caption{Valores reais vs previstos, em 24 horas.}
\end{figure}



\end{document}
